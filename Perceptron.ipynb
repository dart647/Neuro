{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Технологии глубокого обучения и нейронных сетей, МТУСИ\n",
    "\n",
    "## Лабораторная работа 1: Обучение однослойного персептрона методом коррекции по ошибке через дельта-правило\n",
    "\n",
    "__Студент:__ Спивак А.А.\n",
    "\n",
    "__Группа:__ МБД2032"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель работы. \n",
    "\n",
    "    Изучить алгоритм обучения однослойного персептрона методом коррекции по ошибке через дельта-правило.\n",
    "\n",
    "\n",
    "### Задание\n",
    "\n",
    "    В соответствии с вариантом, необходимо обучить нейронную сеть распознавать указанные 4 символа. На каждый символ необходимо подготовить 4 обучающих образа с использованием разных шрифтов. Соответственно, всего будет 16 обучающих образов: 4 образа первым шрифтом, 4 образа, вторым шрифтом и т.д. Тестовая выборка должна содержать по 1 образу на каждый из 4-х символов. Символы должны быть написаны другим шрифтом, который не был использован в обучающей выборке. \n",
    "\n",
    "### Теоретические сведения\n",
    "\n",
    "    Обучение сети включает в себя передачу данных через сеть, использование функции потерь для определения разности между прогнозом и фактической маркировкой, а затем использование этой информации для обновления весов сети, чтобы возврат функции потерь был как можно меньше. Для выполнения обновлений в нейронной сети мы используем оптимизатор.\n",
    "\n",
    "        Ошибкой выхода персептрона:\n",
    "\n",
    "$$ e_j=d_j-y_j $$\n",
    "\n",
    "\n",
    "\n",
    "    Дельта-правило — метод обучения перцептрона по принципу градиентного спуска по поверхности ошибки. Его дальнейшее развитие привело к созданию метода обратного распространения ошибки.\n",
    "\n",
    "    Вес входного сигнала нейрона изменяется в сторону уменьшения ошибки пропорционально величине суммарной ошибки нейрона. Часто вводят коэффициент пропорциональности $\\eta$ , на который умножается величина ошибки. Этот коэффициент называют скоростью или нормой  обучения. \n",
    "    \n",
    "        Формула для корректировки весов:\n",
    "\n",
    "$$ w_{j}(t+1)=w_{j}(t)+\\eta * e_{j} *x_{j}, $$\n",
    "\n",
    "\n",
    "   где $\\eta$ -коэффициент пропорциональности(называют скоростью или нормой  обучения), \n",
    "\n",
    "   $e_{j}$ - величина ошибки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импорт библиотек\n",
    "2. Загрузчик данных и наборы данных\n",
    "3. Создание однослойной нейронной сети \n",
    "4. Уравнение для обучения\n",
    "5. Функция потерь (коррекция по ошибке черех дельта правило )\n",
    "6. Оцениваем точность "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = './data/test'\n",
    "path_train = './data/train'\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание загрузчика датасета "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(root = path_test, transform = transforms)\n",
    "test_dataset = ImageFolder(root = path_train, transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset)\n",
    "test_loader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x141141d1eb0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Однослойный персептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet:\n",
    "    \n",
    "    \"\"\" \n",
    "    Нейронная сеть прямого распрастронения / классификатор \n",
    "    на основе многослойного персептрона\n",
    "    Параметры:\n",
    "    ---------\n",
    "    n_hidden : int (по умолчанию: 30)\n",
    "        количестов скрытых элементов\n",
    "    l2: float (по умолчанию: 0.)\n",
    "        значения лямбда для регулярщации L2\n",
    "        Регуляризация отстутствует, если l2=0 (принято по умолчанию).\n",
    "    epochs: int (по умолчанию: 100)\n",
    "        Количетсов проходов по обучающему набору.\n",
    "    lr: float (по умолчанию: 0.001)\n",
    "        скорость обучения \n",
    "    shuffle: bool (по умолчанию True)\n",
    "        Eсли True, тогда обучающие данные тасуются \n",
    "        каждую эпоху, чтобы предотвратить циклы\n",
    "    minibatch_size: int (по умолчанию 1)\n",
    "        Количество обучаюших образцов на минипакет\n",
    "    seed : int (по умолчанию:None)\n",
    "        Случайное начальное значение для инициализации весов и тасования\n",
    "        \n",
    "    Атрибуты:\n",
    "    --------\n",
    "    eval_ : dict\n",
    "        Словарь, в котором собираются показатели издержек,\n",
    "        правильности при обучении и правильности при испытании\n",
    "        для каждой эпохи во время обучения.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, num_labels,  num_classes, random_seed=123):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # output layer инициализация весов для  слоя + баес\n",
    "        rgen = np.random.RandomState(random_seed)\n",
    "        \n",
    "        ### 784, 6\n",
    "        self.weight_o = rgen.normal(loc = 0.0, scale = 0.001, size = (num_features, num_classes))\n",
    "        \n",
    "        ### 1,6\n",
    "        self.bias_o = np.zeros(num_classes)\n",
    "\n",
    "\n",
    "    def normalize(self, full_volume):\n",
    "        mu = full_volume.mean()\n",
    "        std = np.std(full_volume)\n",
    "        normalized = (full_volume - mu) / std\n",
    "        return normalized\n",
    "\n",
    "    def standardize(self, normalized_data):\n",
    "        standardized_data = (normalized_data - normalized_data.min()) / (normalized_data.max() - normalized_data.min())\n",
    "        return standardized_data\n",
    "\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    def int_to_onehot(self, y, num_labels):\n",
    "        \n",
    "        ''' \n",
    "        Кодирует метки класса в представление с унитарным кодом\n",
    "        \n",
    "        Параметры:\n",
    "        ---------\n",
    "        y: массив, форма = [n_examples]\n",
    "            Целеые значения.\n",
    "            \n",
    "        Возвращает:\n",
    "        ----------\n",
    "        onehot : массив, форма = (n_examples, n_labels)\n",
    "        '''\n",
    "        ## 1,6: [1,0,0,0,0,0] ---[0,1,0,0,0,0]\n",
    "        onehot = np.zeros((y.shape[0], num_labels))\n",
    "        for indx, val in enumerate(y):\n",
    "            onehot[indx, val] = 1\n",
    "\n",
    "        return onehot \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        ## X: {3, 784}  *   weight_o: {784,6}  +  bias_o:{1,6}  = {3,6}\n",
    "        # 1 шаг прямого распространение скларяное произведение X и weight_h\n",
    "        z_out = np.dot(X, self.weight_o) + self.bias_o\n",
    "        \n",
    "        # превращает в меньше единицы\n",
    "        # 2 шаг применение функции активации (сигмоиды) - активация слоя\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        \n",
    "        return  z_out, a_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(num_features = 28 * 28,\n",
    "                      num_labels = 6,\n",
    "                      num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels = 6 ):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "\n",
    "\n",
    "    _, probas = nnet.forward(X)\n",
    "    predicted_labels = np.argmax(probas, axis=1)\n",
    "\n",
    "    onehot_targets = int_to_onehot(y, num_labels = num_labels)\n",
    "    loss = np.mean((onehot_targets - probas) ** 2)\n",
    "    correct_pred += (predicted_labels == y).sum()\n",
    "\n",
    "    num_examples += y.shape[0]\n",
    "    mse += loss\n",
    "\n",
    "    mse = mse\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader,  num_epochs, learning_rate=0.1):\n",
    "    epoch_loss = []\n",
    "    _loss = []\n",
    "    \n",
    "    epoch_train_acc = []\n",
    "    _train_acc = []\n",
    "    \n",
    "    epoch_valid_acc = []\n",
    "    _valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "\n",
    "        \n",
    "        for X_train_mini, y_train_mini in train_loader:\n",
    "            \n",
    "            ### preprocesing\n",
    "            \n",
    "            ##сплющивание тензора 3,28,28 --> 3.784\n",
    "            X_train_mini = torch.flatten(X_train_mini, start_dim = 2, end_dim = 3)\n",
    "            \n",
    "            ## меням тип на np.array 3, 785,1 \n",
    "            X_train_mini = np.array(X_train_mini) \n",
    "            \n",
    "            ## убиарем ось описывабщший батч\n",
    "            X_train_mini = np.squeeze(X_train_mini)\n",
    "            \n",
    "            # перемещавем ось\n",
    "            #X_train_mini = X_train_mini.swapaxes(0,2) \n",
    "            #print(X_train_mini .shape)\n",
    "            #стандартизируем данные\n",
    "            X_train_mini = model.standardize(model.normalize(X_train_mini))\n",
    "\n",
    "            \n",
    "            y_train_mini = np.array(y_train_mini)\n",
    "            #print(y_train_mini)\n",
    "\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            z_out, a_out = model.forward(X_train_mini)\n",
    "            #print(\"a_out\", a_out)\n",
    "            \n",
    "            #### Compute delta ####\n",
    "            onehot_target = model.int_to_onehot(y_train_mini, num_labels = 6)\n",
    "            #print('onehot_target', onehot_target)\n",
    "            \n",
    "            delta = (onehot_target  - a_out ) * learning_rate\n",
    "            #print('delta', delta)\n",
    "            \n",
    "            delta_weight = np.dot(delta.T, X_train_mini )\n",
    "            #print('delta_weight', delta_weight)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_o +=  delta_weight.T\n",
    "            #print('weight_o', model.weight_o)\n",
    "\n",
    "            model.bias_o += np.sum(delta, axis = 0)\n",
    "            #print('bias_o', model.bias_o)\n",
    "            \n",
    "            ##loss\n",
    "            predicted_labels = np.argmax(a_out, axis = 1)\n",
    "            train_acc = (y_train_mini == predicted_labels)\n",
    "\n",
    "            train_mse =  ((onehot_target - a_out) ** 2)\n",
    "            \n",
    "            _train_acc.append(train_acc)\n",
    "            _loss.append(train_mse)\n",
    "            \n",
    "        for X_valid_mini, y_valid_mini in valid_loader:\n",
    "            \n",
    "            ##сплющивание тензора 3,28,28 --> 3.784\n",
    "            X_valid_mini = torch.flatten(X_valid_mini, start_dim=2, end_dim=3)\n",
    "            \n",
    "            ## меням тип на np.array 3, 785,1 \n",
    "            X_valid_mini = np.array(X_valid_mini) \n",
    "            \n",
    "            ## убиарем ось описывабщший батч\n",
    "            X_valid_mini = np.squeeze(X_valid_mini)\n",
    "            \n",
    "            # перемещавем ось\n",
    "            #X_train_mini = X_train_mini.swapaxes(0,2) \n",
    "\n",
    "            \n",
    "            #стандартизируем данные\n",
    "            X_valid_mini = model.standardize(model.normalize(X_valid_mini))\n",
    "\n",
    "            y_valid_mini = np.array(y_valid_mini)\n",
    "\n",
    "            \n",
    "            ##loss\n",
    "            \n",
    "            #### Compute outputs ####\n",
    "            _, a_v_out = model.forward(X_valid_mini)\n",
    "            \n",
    "            predicted_labels = np.argmax(a_v_out, axis = 1)\n",
    "            \n",
    "            \n",
    "            valid_acc = (y_valid_mini == predicted_labels)\n",
    "            _valid_acc.append(valid_acc)\n",
    "\n",
    "            \n",
    "        #### Epoch Logging ####        \n",
    "        #train_mse, train_acc = compute_mse_and_acc(model, X_train_mini, y_train_mini)\n",
    "        #valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        \n",
    "        \n",
    "        train_acc = np.mean(_train_acc) * 100\n",
    "        train_mse = np.mean(_loss)\n",
    "        \n",
    "        valid_acc = np.mean(_valid_acc) * 100\n",
    "        \n",
    "\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e + 1:03d}/{num_epochs:.2f} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100.00 | Train MSE: 0.21 | Train Acc: 0.00% | Valid Acc: 79.17%\n",
      "Epoch: 002/100.00 | Train MSE: 0.15 | Train Acc: 33.33% | Valid Acc: 87.50%\n",
      "Epoch: 003/100.00 | Train MSE: 0.12 | Train Acc: 55.56% | Valid Acc: 91.67%\n",
      "Epoch: 004/100.00 | Train MSE: 0.09 | Train Acc: 66.67% | Valid Acc: 93.75%\n",
      "Epoch: 005/100.00 | Train MSE: 0.08 | Train Acc: 73.33% | Valid Acc: 95.00%\n",
      "Epoch: 006/100.00 | Train MSE: 0.07 | Train Acc: 77.78% | Valid Acc: 95.83%\n",
      "Epoch: 007/100.00 | Train MSE: 0.06 | Train Acc: 80.95% | Valid Acc: 96.43%\n",
      "Epoch: 008/100.00 | Train MSE: 0.05 | Train Acc: 83.33% | Valid Acc: 96.88%\n",
      "Epoch: 009/100.00 | Train MSE: 0.05 | Train Acc: 85.19% | Valid Acc: 97.22%\n",
      "Epoch: 010/100.00 | Train MSE: 0.04 | Train Acc: 86.67% | Valid Acc: 97.50%\n",
      "Epoch: 011/100.00 | Train MSE: 0.04 | Train Acc: 87.88% | Valid Acc: 97.73%\n",
      "Epoch: 012/100.00 | Train MSE: 0.04 | Train Acc: 88.89% | Valid Acc: 97.92%\n",
      "Epoch: 013/100.00 | Train MSE: 0.03 | Train Acc: 89.74% | Valid Acc: 98.08%\n",
      "Epoch: 014/100.00 | Train MSE: 0.03 | Train Acc: 90.48% | Valid Acc: 98.21%\n",
      "Epoch: 015/100.00 | Train MSE: 0.03 | Train Acc: 91.11% | Valid Acc: 98.33%\n",
      "Epoch: 016/100.00 | Train MSE: 0.03 | Train Acc: 91.67% | Valid Acc: 98.44%\n",
      "Epoch: 017/100.00 | Train MSE: 0.03 | Train Acc: 92.16% | Valid Acc: 98.53%\n",
      "Epoch: 018/100.00 | Train MSE: 0.02 | Train Acc: 92.59% | Valid Acc: 98.61%\n",
      "Epoch: 019/100.00 | Train MSE: 0.02 | Train Acc: 92.98% | Valid Acc: 98.68%\n",
      "Epoch: 020/100.00 | Train MSE: 0.02 | Train Acc: 93.33% | Valid Acc: 98.75%\n",
      "Epoch: 021/100.00 | Train MSE: 0.02 | Train Acc: 93.65% | Valid Acc: 98.81%\n",
      "Epoch: 022/100.00 | Train MSE: 0.02 | Train Acc: 93.94% | Valid Acc: 98.86%\n",
      "Epoch: 023/100.00 | Train MSE: 0.02 | Train Acc: 94.20% | Valid Acc: 98.91%\n",
      "Epoch: 024/100.00 | Train MSE: 0.02 | Train Acc: 94.44% | Valid Acc: 98.96%\n",
      "Epoch: 025/100.00 | Train MSE: 0.02 | Train Acc: 94.67% | Valid Acc: 99.00%\n",
      "Epoch: 026/100.00 | Train MSE: 0.02 | Train Acc: 94.87% | Valid Acc: 99.04%\n",
      "Epoch: 027/100.00 | Train MSE: 0.02 | Train Acc: 95.06% | Valid Acc: 99.07%\n",
      "Epoch: 028/100.00 | Train MSE: 0.02 | Train Acc: 95.24% | Valid Acc: 99.11%\n",
      "Epoch: 029/100.00 | Train MSE: 0.02 | Train Acc: 95.40% | Valid Acc: 99.14%\n",
      "Epoch: 030/100.00 | Train MSE: 0.01 | Train Acc: 95.56% | Valid Acc: 99.17%\n",
      "Epoch: 031/100.00 | Train MSE: 0.01 | Train Acc: 95.70% | Valid Acc: 99.19%\n",
      "Epoch: 032/100.00 | Train MSE: 0.01 | Train Acc: 95.83% | Valid Acc: 99.22%\n",
      "Epoch: 033/100.00 | Train MSE: 0.01 | Train Acc: 95.96% | Valid Acc: 99.24%\n",
      "Epoch: 034/100.00 | Train MSE: 0.01 | Train Acc: 96.08% | Valid Acc: 99.26%\n",
      "Epoch: 035/100.00 | Train MSE: 0.01 | Train Acc: 96.19% | Valid Acc: 99.29%\n",
      "Epoch: 036/100.00 | Train MSE: 0.01 | Train Acc: 96.30% | Valid Acc: 99.31%\n",
      "Epoch: 037/100.00 | Train MSE: 0.01 | Train Acc: 96.40% | Valid Acc: 99.32%\n",
      "Epoch: 038/100.00 | Train MSE: 0.01 | Train Acc: 96.49% | Valid Acc: 99.34%\n",
      "Epoch: 039/100.00 | Train MSE: 0.01 | Train Acc: 96.58% | Valid Acc: 99.36%\n",
      "Epoch: 040/100.00 | Train MSE: 0.01 | Train Acc: 96.67% | Valid Acc: 99.38%\n",
      "Epoch: 041/100.00 | Train MSE: 0.01 | Train Acc: 96.75% | Valid Acc: 99.39%\n",
      "Epoch: 042/100.00 | Train MSE: 0.01 | Train Acc: 96.83% | Valid Acc: 99.40%\n",
      "Epoch: 043/100.00 | Train MSE: 0.01 | Train Acc: 96.90% | Valid Acc: 99.42%\n",
      "Epoch: 044/100.00 | Train MSE: 0.01 | Train Acc: 96.97% | Valid Acc: 99.43%\n",
      "Epoch: 045/100.00 | Train MSE: 0.01 | Train Acc: 97.04% | Valid Acc: 99.44%\n",
      "Epoch: 046/100.00 | Train MSE: 0.01 | Train Acc: 97.10% | Valid Acc: 99.46%\n",
      "Epoch: 047/100.00 | Train MSE: 0.01 | Train Acc: 97.16% | Valid Acc: 99.47%\n",
      "Epoch: 048/100.00 | Train MSE: 0.01 | Train Acc: 97.22% | Valid Acc: 99.48%\n",
      "Epoch: 049/100.00 | Train MSE: 0.01 | Train Acc: 97.28% | Valid Acc: 99.49%\n",
      "Epoch: 050/100.00 | Train MSE: 0.01 | Train Acc: 97.33% | Valid Acc: 99.50%\n",
      "Epoch: 051/100.00 | Train MSE: 0.01 | Train Acc: 97.39% | Valid Acc: 99.51%\n",
      "Epoch: 052/100.00 | Train MSE: 0.01 | Train Acc: 97.44% | Valid Acc: 99.52%\n",
      "Epoch: 053/100.00 | Train MSE: 0.01 | Train Acc: 97.48% | Valid Acc: 99.53%\n",
      "Epoch: 054/100.00 | Train MSE: 0.01 | Train Acc: 97.53% | Valid Acc: 99.54%\n",
      "Epoch: 055/100.00 | Train MSE: 0.01 | Train Acc: 97.58% | Valid Acc: 99.55%\n",
      "Epoch: 056/100.00 | Train MSE: 0.01 | Train Acc: 97.62% | Valid Acc: 99.55%\n",
      "Epoch: 057/100.00 | Train MSE: 0.01 | Train Acc: 97.66% | Valid Acc: 99.56%\n",
      "Epoch: 058/100.00 | Train MSE: 0.01 | Train Acc: 97.70% | Valid Acc: 99.57%\n",
      "Epoch: 059/100.00 | Train MSE: 0.01 | Train Acc: 97.74% | Valid Acc: 99.58%\n",
      "Epoch: 060/100.00 | Train MSE: 0.01 | Train Acc: 97.78% | Valid Acc: 99.58%\n",
      "Epoch: 061/100.00 | Train MSE: 0.01 | Train Acc: 97.81% | Valid Acc: 99.59%\n",
      "Epoch: 062/100.00 | Train MSE: 0.01 | Train Acc: 97.85% | Valid Acc: 99.60%\n",
      "Epoch: 063/100.00 | Train MSE: 0.01 | Train Acc: 97.88% | Valid Acc: 99.60%\n",
      "Epoch: 064/100.00 | Train MSE: 0.01 | Train Acc: 97.92% | Valid Acc: 99.61%\n",
      "Epoch: 065/100.00 | Train MSE: 0.01 | Train Acc: 97.95% | Valid Acc: 99.62%\n",
      "Epoch: 066/100.00 | Train MSE: 0.01 | Train Acc: 97.98% | Valid Acc: 99.62%\n",
      "Epoch: 067/100.00 | Train MSE: 0.01 | Train Acc: 98.01% | Valid Acc: 99.63%\n",
      "Epoch: 068/100.00 | Train MSE: 0.01 | Train Acc: 98.04% | Valid Acc: 99.63%\n",
      "Epoch: 069/100.00 | Train MSE: 0.01 | Train Acc: 98.07% | Valid Acc: 99.64%\n",
      "Epoch: 070/100.00 | Train MSE: 0.01 | Train Acc: 98.10% | Valid Acc: 99.64%\n",
      "Epoch: 071/100.00 | Train MSE: 0.01 | Train Acc: 98.12% | Valid Acc: 99.65%\n",
      "Epoch: 072/100.00 | Train MSE: 0.01 | Train Acc: 98.15% | Valid Acc: 99.65%\n",
      "Epoch: 073/100.00 | Train MSE: 0.01 | Train Acc: 98.17% | Valid Acc: 99.66%\n",
      "Epoch: 074/100.00 | Train MSE: 0.01 | Train Acc: 98.20% | Valid Acc: 99.66%\n",
      "Epoch: 075/100.00 | Train MSE: 0.01 | Train Acc: 98.22% | Valid Acc: 99.67%\n",
      "Epoch: 076/100.00 | Train MSE: 0.01 | Train Acc: 98.25% | Valid Acc: 99.67%\n",
      "Epoch: 077/100.00 | Train MSE: 0.01 | Train Acc: 98.27% | Valid Acc: 99.68%\n",
      "Epoch: 078/100.00 | Train MSE: 0.01 | Train Acc: 98.29% | Valid Acc: 99.68%\n",
      "Epoch: 079/100.00 | Train MSE: 0.01 | Train Acc: 98.31% | Valid Acc: 99.68%\n",
      "Epoch: 080/100.00 | Train MSE: 0.01 | Train Acc: 98.33% | Valid Acc: 99.69%\n",
      "Epoch: 081/100.00 | Train MSE: 0.01 | Train Acc: 98.35% | Valid Acc: 99.69%\n",
      "Epoch: 082/100.00 | Train MSE: 0.01 | Train Acc: 98.37% | Valid Acc: 99.70%\n",
      "Epoch: 083/100.00 | Train MSE: 0.01 | Train Acc: 98.39% | Valid Acc: 99.70%\n",
      "Epoch: 084/100.00 | Train MSE: 0.01 | Train Acc: 98.41% | Valid Acc: 99.70%\n",
      "Epoch: 085/100.00 | Train MSE: 0.01 | Train Acc: 98.43% | Valid Acc: 99.71%\n",
      "Epoch: 086/100.00 | Train MSE: 0.01 | Train Acc: 98.45% | Valid Acc: 99.71%\n",
      "Epoch: 087/100.00 | Train MSE: 0.01 | Train Acc: 98.47% | Valid Acc: 99.71%\n",
      "Epoch: 088/100.00 | Train MSE: 0.01 | Train Acc: 98.48% | Valid Acc: 99.72%\n",
      "Epoch: 089/100.00 | Train MSE: 0.00 | Train Acc: 98.50% | Valid Acc: 99.72%\n",
      "Epoch: 090/100.00 | Train MSE: 0.00 | Train Acc: 98.52% | Valid Acc: 99.72%\n",
      "Epoch: 091/100.00 | Train MSE: 0.00 | Train Acc: 98.53% | Valid Acc: 99.73%\n",
      "Epoch: 092/100.00 | Train MSE: 0.00 | Train Acc: 98.55% | Valid Acc: 99.73%\n",
      "Epoch: 093/100.00 | Train MSE: 0.00 | Train Acc: 98.57% | Valid Acc: 99.73%\n",
      "Epoch: 094/100.00 | Train MSE: 0.00 | Train Acc: 98.58% | Valid Acc: 99.73%\n",
      "Epoch: 095/100.00 | Train MSE: 0.00 | Train Acc: 98.60% | Valid Acc: 99.74%\n",
      "Epoch: 096/100.00 | Train MSE: 0.00 | Train Acc: 98.61% | Valid Acc: 99.74%\n",
      "Epoch: 097/100.00 | Train MSE: 0.00 | Train Acc: 98.63% | Valid Acc: 99.74%\n",
      "Epoch: 098/100.00 | Train MSE: 0.00 | Train Acc: 98.64% | Valid Acc: 99.74%\n",
      "Epoch: 099/100.00 | Train MSE: 0.00 | Train Acc: 98.65% | Valid Acc: 99.75%\n",
      "Epoch: 100/100.00 | Train MSE: 0.00 | Train Acc: 98.67% | Valid Acc: 99.75%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(647) # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, train_loader, test_loader, num_epochs = 100, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08563060e-03,  9.97345447e-04,  2.82978498e-04,\n",
       "        -1.50629471e-03, -5.78600252e-04,  1.65143654e-03],\n",
       "       [-2.42667924e-03, -4.28912629e-04,  1.26593626e-03,\n",
       "        -8.66740402e-04, -6.78886152e-04, -9.47089689e-05],\n",
       "       [ 1.49138963e-03, -6.38901997e-04, -4.43981960e-04,\n",
       "        -4.34351276e-04,  2.20593008e-03,  2.18678609e-03],\n",
       "       ...,\n",
       "       [-4.54652365e-04,  2.47005806e-05, -2.05011003e-03,\n",
       "         6.39761168e-04,  1.42078645e-03,  1.24663078e-03],\n",
       "       [-1.04379345e-03,  5.98483986e-04,  5.16285804e-05,\n",
       "        -6.19840380e-04,  5.24523253e-04,  6.66086969e-04],\n",
       "       [ 4.48142609e-04,  4.94382376e-04, -9.34362341e-05,\n",
       "         1.65065342e-03, -8.45004127e-04,  3.95839030e-04]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка производительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Наибольший прирост точности обучения проявляется в первых 10 эпохах, далее схождение замедляется. На 100 эпохе все еще происходит небольшой спад, по этому при продолжении обучения точность может стать еще больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc)\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    В итоге схождение обучения и проверки достигается увеличением числа эпох. \n",
    "    На 89 эпохе обучение можно считать завершенным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Лабораторная работа 2: Обучение однослойного персептрона методом стохастического градиентного спуска\n",
    "\n",
    "__Студент:__ Спивак А.А.\n",
    "\n",
    "__Группа:__ МБД2032\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цель работы. \n",
    "\n",
    "    Изучить алгоритм обучения однослойного персептрона методом стохастического градиентного спуска.\n",
    "\n",
    "\n",
    "### Задание\n",
    "\n",
    "    Построить и обучить нейронную сеть для распознавания цифровых рукописных символов из базы данных MNIST (Mixed National Institute of Standards and Technology database). Нейронная сеть должна корректно распознавать образы из тестовой выборки в большинстве случаев. Общий процент ошибки распознавания образов не должен быть выше 20%.\n",
    "\n",
    "### Теоретические сведения. \n",
    "\n",
    "Критерии останова алгоритма обучения могут быть следующими:\n",
    "\n",
    "* Значение ошибки ε для текущего обучающего вектора, вычисляемое на текущем случайно взятом обучающем векторе не превышает заданного заранее установленного порогового значения εпорог, близкого к нулю: ε<ε_порог.\n",
    "* Превышен установленный лимит количества эпох.\n",
    "* Значение общей ошибки всей сети меняется незначительно на протяжении нескольких эпох.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ход выполнения работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка предподготовленных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = np.load('mnist_scaled.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_train', 'y_train', 'X_test', 'y_test', 'X_valid', 'y_valid']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = [mnist[f] for f in mnist.files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (55000, 784))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetMLP:\n",
    "    \n",
    "    \"\"\" \n",
    "    Нейронная сеть прямого распрастронения / классификатор \n",
    "    на основе многослойного персептрона\n",
    "    Параметры:\n",
    "    ---------\n",
    "    n_hidden : int (по умолчанию: 30)\n",
    "        количестов скрытых элементов\n",
    "    l2: float (по умолчанию: 0.)\n",
    "        значения лямбда для регулярщации L2\n",
    "        Регуляризация отстутствует, если l2=0 (принято по умолчанию).\n",
    "    epochs: int (по умолчанию: 100)\n",
    "        Количетсов проходов по обучающему набору.\n",
    "    lr: float (по умолчанию: 0.001)\n",
    "        скорость обучения \n",
    "    shuffle: bool (по умолчанию True)\n",
    "        Eсли True, тогда обучающие данные тасуются \n",
    "        каждую эпоху, чтобы предотвратить циклы\n",
    "    minibatch_size: int (по умолчанию 1)\n",
    "        Количество обучаюших образцов на минипакет\n",
    "    seed : int (по умолчанию:None)\n",
    "        Случайное начальное значение для инициализации весов и тасования\n",
    "        \n",
    "    Атрибуты:\n",
    "    --------\n",
    "    eval_ : dict\n",
    "        Словарь, в котором собираются показатели издержек,\n",
    "        правильности при обучении и правильности при испытании\n",
    "        для каждой эпохи во время обучения.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_features, num_labels,  num_classes, random_seed = 123):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # output layer инициализация весов для  слоя + баес\n",
    "        rgen = np.random.RandomState(random_seed)\n",
    "        self.weight_o = rgen.normal(loc = 0.0, scale = 0.001, size = ( num_classes,num_features ))\n",
    "        self.bias_o = np.zeros(self.num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1. / (1. + np.exp(-z))\n",
    "    \n",
    "    def int_to_onehot(self, y, num_labels):\n",
    "        \n",
    "        ''' \n",
    "        Кодирует метки класса в представление с унитарным кодом\n",
    "        \n",
    "        Параметры:\n",
    "        ---------\n",
    "        y: массив, форма = [n_examples]\n",
    "            Целеые значения.\n",
    "            \n",
    "        Возвращает:\n",
    "        ----------\n",
    "        onehot : массив, форма = (n_examples, n_labels)\n",
    "        '''\n",
    "        onehot = np.zeros((y.shape[0], num_labels))\n",
    "        for indx, val in enumerate(y):\n",
    "            onehot[indx, val] = 1\n",
    "\n",
    "        return onehot \n",
    "    def forward(self, X):\n",
    "        \n",
    "        # 1 шаг прямого распространение скларяное произведение X и weight_h\n",
    "        z_out = np.dot(X, self.weight_o.T) + self.bias_o\n",
    "        \n",
    "        # 2 шаг применение функции активации (сигмоиды) - активация слоя\n",
    "        a_out = self.sigmoid(z_out)\n",
    "        \n",
    "        \n",
    "        return  X, a_out\n",
    "    \n",
    "    \n",
    "    def backward(self, x, a_out, y):\n",
    "        \n",
    "        ##########################\n",
    "        #Обратоне распространение#\n",
    "        ##########################\n",
    "        #########################\n",
    "        ### Output layer weights#\n",
    "        #########################\n",
    "        \n",
    "        #onehot encoding\n",
    "        y_onehot = self.int_to_onehot(y, self.num_classes)\n",
    "        \n",
    "        # Part 1: dLoss/dOutWeights\n",
    "        ## = dLoss/dOutAct(a_out) * dOutAct(a_out)/dOutNet(z_out) * dOutNet(z_out)/dOutWeight\n",
    "        ## where DeltaOut = dLoss/dOutAct * dOutAct/dOutNet\n",
    "        ## for convenient re-use\n",
    "        \n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss__d_a_out = 2.*(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out) # sigmoid derivative\n",
    "\n",
    "        # output dim: [n_examples, n_classes]\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out # \"delta (rule) placeholder\"\n",
    "\n",
    "        # gradient for output weights\n",
    "        \n",
    "        # [n_examples, n_hidden]\n",
    "        d_z_out__dw_out = x\n",
    "        \n",
    "        # input dim: [n_classes, n_examples] dot [n_examples, n_hidden]\n",
    "        # output dim: [n_classes, n_hidden]\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis = 0)\n",
    "        \n",
    "\n",
    "        return d_loss__dw_out, d_loss__db_out\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetMLP(num_features = 28 * 28,\n",
    "                     num_labels = 10,\n",
    "                   num_classes = 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size=100\n",
    "num_epochs =50\n",
    "\n",
    "def minibatch_generator(X, y, minibacth_size=50):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(indices)\n",
    "     \n",
    "    #итерация по мини-пакетам\n",
    "    for start_batch_indx in range(0, indices.shape[0] - minibatch_size + 1, minibatch_size):\n",
    "        indx = indices[start_batch_indx: start_batch_indx + minibatch_size]\n",
    "        yield X[indx], y[indx]\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels = 10, minibatch_size = 100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "        \n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels = np.argmax(probas, axis = 1)\n",
    "        \n",
    "        onehot_targets = nnet.int_to_onehot(targets, num_labels = num_labels)\n",
    "        loss = np.mean((onehot_targets - probas) ** 2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "        \n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "\n",
    "    mse = mse/i\n",
    "    acc = correct_pred/num_examples\n",
    "    return mse, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial valid MSE: 0.3\n",
      "Initial valid accuracy: 10.2%\n"
     ]
    }
   ],
   "source": [
    "mse, acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE: {mse:.1f}')\n",
    "print(f'Initial valid accuracy: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs, learning_rate=0.1):\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    Обновляем веса \n",
    "    \n",
    "    '''\n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "    \n",
    "    for e in range(num_epochs):\n",
    "\n",
    "        # iterate over minibatches\n",
    "        minibatch_gen = minibatch_generator(\n",
    "            X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            _, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            d_loss__d_w_out, d_loss__d_b_out = \\\n",
    "                model.backward(X_train_mini, a_out, y_train_mini)\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weight_o -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_o -= learning_rate * d_loss__d_b_out\n",
    "\n",
    "        #### Epoch Logging ####        \n",
    "        train_mse, train_acc = compute_mse_and_acc(model, X_train, y_train)\n",
    "        valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc * 100, valid_acc * 100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e+1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/060 | Train MSE: 0.09 | Train Acc: 11.94% | Valid Acc: 12.02%\n",
      "Epoch: 002/060 | Train MSE: 0.08 | Train Acc: 29.09% | Valid Acc: 29.16%\n",
      "Epoch: 003/060 | Train MSE: 0.06 | Train Acc: 46.94% | Valid Acc: 47.22%\n",
      "Epoch: 004/060 | Train MSE: 0.06 | Train Acc: 47.13% | Valid Acc: 47.26%\n",
      "Epoch: 005/060 | Train MSE: 0.05 | Train Acc: 55.43% | Valid Acc: 55.52%\n",
      "Epoch: 006/060 | Train MSE: 0.05 | Train Acc: 55.94% | Valid Acc: 56.12%\n",
      "Epoch: 007/060 | Train MSE: 0.04 | Train Acc: 71.48% | Valid Acc: 71.38%\n",
      "Epoch: 008/060 | Train MSE: 0.04 | Train Acc: 71.77% | Valid Acc: 71.92%\n",
      "Epoch: 009/060 | Train MSE: 0.04 | Train Acc: 71.84% | Valid Acc: 71.94%\n",
      "Epoch: 010/060 | Train MSE: 0.04 | Train Acc: 77.83% | Valid Acc: 77.40%\n",
      "Epoch: 011/060 | Train MSE: 0.02 | Train Acc: 90.55% | Valid Acc: 90.24%\n",
      "Epoch: 012/060 | Train MSE: 0.02 | Train Acc: 90.80% | Valid Acc: 90.30%\n",
      "Epoch: 013/060 | Train MSE: 0.02 | Train Acc: 90.83% | Valid Acc: 90.32%\n",
      "Epoch: 014/060 | Train MSE: 0.02 | Train Acc: 91.03% | Valid Acc: 90.62%\n",
      "Epoch: 015/060 | Train MSE: 0.02 | Train Acc: 91.36% | Valid Acc: 90.98%\n",
      "Epoch: 016/060 | Train MSE: 0.02 | Train Acc: 91.45% | Valid Acc: 91.10%\n",
      "Epoch: 017/060 | Train MSE: 0.02 | Train Acc: 91.50% | Valid Acc: 91.04%\n",
      "Epoch: 018/060 | Train MSE: 0.02 | Train Acc: 91.47% | Valid Acc: 91.08%\n",
      "Epoch: 019/060 | Train MSE: 0.02 | Train Acc: 91.46% | Valid Acc: 91.02%\n",
      "Epoch: 020/060 | Train MSE: 0.02 | Train Acc: 91.48% | Valid Acc: 90.98%\n",
      "Epoch: 021/060 | Train MSE: 0.02 | Train Acc: 91.63% | Valid Acc: 91.16%\n",
      "Epoch: 022/060 | Train MSE: 0.02 | Train Acc: 91.65% | Valid Acc: 91.18%\n",
      "Epoch: 023/060 | Train MSE: 0.02 | Train Acc: 91.42% | Valid Acc: 90.80%\n",
      "Epoch: 024/060 | Train MSE: 0.02 | Train Acc: 91.77% | Valid Acc: 91.28%\n",
      "Epoch: 025/060 | Train MSE: 0.02 | Train Acc: 91.70% | Valid Acc: 91.10%\n",
      "Epoch: 026/060 | Train MSE: 0.02 | Train Acc: 91.70% | Valid Acc: 90.90%\n",
      "Epoch: 027/060 | Train MSE: 0.02 | Train Acc: 91.75% | Valid Acc: 91.16%\n",
      "Epoch: 028/060 | Train MSE: 0.02 | Train Acc: 91.90% | Valid Acc: 91.22%\n",
      "Epoch: 029/060 | Train MSE: 0.02 | Train Acc: 91.84% | Valid Acc: 91.18%\n",
      "Epoch: 030/060 | Train MSE: 0.02 | Train Acc: 91.99% | Valid Acc: 91.24%\n",
      "Epoch: 031/060 | Train MSE: 0.02 | Train Acc: 92.02% | Valid Acc: 91.28%\n",
      "Epoch: 032/060 | Train MSE: 0.02 | Train Acc: 91.91% | Valid Acc: 91.10%\n",
      "Epoch: 033/060 | Train MSE: 0.02 | Train Acc: 91.79% | Valid Acc: 91.10%\n",
      "Epoch: 034/060 | Train MSE: 0.02 | Train Acc: 91.97% | Valid Acc: 91.30%\n",
      "Epoch: 035/060 | Train MSE: 0.02 | Train Acc: 92.10% | Valid Acc: 91.52%\n",
      "Epoch: 036/060 | Train MSE: 0.02 | Train Acc: 92.02% | Valid Acc: 91.38%\n",
      "Epoch: 037/060 | Train MSE: 0.02 | Train Acc: 91.90% | Valid Acc: 91.32%\n",
      "Epoch: 038/060 | Train MSE: 0.02 | Train Acc: 92.17% | Valid Acc: 91.58%\n",
      "Epoch: 039/060 | Train MSE: 0.02 | Train Acc: 91.94% | Valid Acc: 91.10%\n",
      "Epoch: 040/060 | Train MSE: 0.02 | Train Acc: 91.96% | Valid Acc: 91.20%\n",
      "Epoch: 041/060 | Train MSE: 0.02 | Train Acc: 92.02% | Valid Acc: 91.42%\n",
      "Epoch: 042/060 | Train MSE: 0.01 | Train Acc: 92.16% | Valid Acc: 91.30%\n",
      "Epoch: 043/060 | Train MSE: 0.01 | Train Acc: 92.21% | Valid Acc: 91.34%\n",
      "Epoch: 044/060 | Train MSE: 0.01 | Train Acc: 92.15% | Valid Acc: 91.28%\n",
      "Epoch: 045/060 | Train MSE: 0.02 | Train Acc: 92.04% | Valid Acc: 91.08%\n",
      "Epoch: 046/060 | Train MSE: 0.01 | Train Acc: 92.12% | Valid Acc: 91.26%\n",
      "Epoch: 047/060 | Train MSE: 0.01 | Train Acc: 92.20% | Valid Acc: 91.28%\n",
      "Epoch: 048/060 | Train MSE: 0.01 | Train Acc: 92.24% | Valid Acc: 91.32%\n",
      "Epoch: 049/060 | Train MSE: 0.01 | Train Acc: 92.17% | Valid Acc: 91.56%\n",
      "Epoch: 050/060 | Train MSE: 0.01 | Train Acc: 92.25% | Valid Acc: 91.38%\n",
      "Epoch: 051/060 | Train MSE: 0.01 | Train Acc: 92.14% | Valid Acc: 91.16%\n",
      "Epoch: 052/060 | Train MSE: 0.01 | Train Acc: 92.19% | Valid Acc: 91.52%\n",
      "Epoch: 053/060 | Train MSE: 0.01 | Train Acc: 92.17% | Valid Acc: 91.28%\n",
      "Epoch: 054/060 | Train MSE: 0.01 | Train Acc: 92.19% | Valid Acc: 91.38%\n",
      "Epoch: 055/060 | Train MSE: 0.01 | Train Acc: 92.27% | Valid Acc: 91.40%\n",
      "Epoch: 056/060 | Train MSE: 0.01 | Train Acc: 92.23% | Valid Acc: 91.32%\n",
      "Epoch: 057/060 | Train MSE: 0.01 | Train Acc: 92.28% | Valid Acc: 91.46%\n",
      "Epoch: 058/060 | Train MSE: 0.01 | Train Acc: 92.27% | Valid Acc: 91.48%\n",
      "Epoch: 059/060 | Train MSE: 0.01 | Train Acc: 92.31% | Valid Acc: 91.32%\n",
      "Epoch: 060/060 | Train MSE: 0.01 | Train Acc: 92.31% | Valid Acc: 91.46%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(647) # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs = 60, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    Наибольший прирост точности обучения проявляется в первых 11 эпохах, далее схождение сильно замедляется. На 60 эпохе спада не наблюдается, по этому обучение можно считать законченным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc)\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "\n",
    "    В итоге схождение обучения и проверки достигается увеличением числа эпох. \n",
    "    На 59 эпохе обучение можно считать завершенным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог:\n",
    "    \n",
    "    Для правильного обучение нейронной сети стоит обращать внимание на сходимость обучения с тестовыми значениями. Это позволяет судить о том справляется ли нейронная сеть с обучением или стоит подкорректировать модели для обучения или параметры сети."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
